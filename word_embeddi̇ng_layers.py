# -*- coding: utf-8 -*-
"""WORD EMBEDDİNG LAYERS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16KlqIwXkIez1Vqyx64W-RMbYyabRdJuX
"""

!pip install tensorflow-gpu

import tensorflow as tf
print(tf.__version__)

sent = ["the glass of milk",
        "the glass of juice",
        "the cup of tea",
        "I am a good boy",
        "I am a good Data Science",
        "Understand the meaning of words",
        "your videos are good"]

sent

voc_size = 1000

from tensorflow.keras.preprocessing.text import one_hot

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential

onehot_repr = [one_hot(words,voc_size) for words in sent]
print(onehot_repr)

# the glass of milk --> CÜMLEDE Kİ BİRİNCİ KELİME 37.İNDEKSTE 1 DİR DİYE GİDER.

import numpy as np

## pre padding
## ön dolgu

sent_length=8
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs)

## 10 feature dimesnions
## 10 özellik boyutu
dim = 10

model = Sequential()
model.add(Embedding(voc_size,10,input_length = sent_length))
model.compile("adam","mse")

model.summary()
# MODELİN ÖZETİ.

##'the glass of milk',
embedded_docs[0]

model.predict(embedded_docs[0])

print(model.predict(embedded_docs))

text = ["The world is a better place",
        "Marvel series is my favourite movie",
        "I Like DC movies",
        "The cat is eating the food",
        "Tom and Jerry is my favourite movie"]

text

kelime_uzunluğu = 500

onehot_text = [one_hot(words,kelime_uzunluğu)for words in text]
print(onehot_text)

import numpy as np

gönderilen_uzunluk = 10

embedding_text = pad_sequences(onehot_text,maxlen =gönderilen_uzunluk,padding="pre")
print(embedding_text)

ozellik_boyutu = 10

Model = Sequential()
Model.add(Embedding(kelime_uzunluğu,10,input_length = gönderilen_uzunluk))
Model.compile("adam","mse")

Model.summary()

embedding_text[0]

Model.predict(embedding_text[0])

print(Model.predict(embedding_text))

